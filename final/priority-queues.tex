%!TEX root = draft.tex
\newcommand{\seqPQ}{\mathsf{SeqPQ}}

\section{The Priority Queue ADT}
\label{sec:priority queue and data-independence}

We consider priority queues whose interface contains two methods $\textit{put}$ and $\textit{rm}$ for adding and respectively, removing a value. Each value is assigned with a priority when being added to the data structure (by calling $\textit{put}$) and the remove method $\textit{rm}$ removes a value with a minimal priority. For generality, we assume that the set of priorities is partially-ordered. Incomparable priorities can be removed in any order. When multiple values are assigned with the same priority, $\textit{rm}$ returns the least recent value. Also, when the set of values stored in the priority queue is empty, $\textit{rm}$ returns the distinguished value $\textit{empty}$. In this section, we formalize (concurrent) executions and implementations, introduce a set of properties satisfied by all the implementations we are aware of, and recall the standard correctness criterion for concurrent implementations of ADTs known as \emph{linearizability}~\cite{journals/toplas/HerlihyW90}.
%
%recall the notion of \emph{linearizability}, the standard correctness criterion for concurrent implementations of priority queues (
%
%Concurrent implementations of the priority queue allow the methods $\textit{put}$ and $\textit{rm}$ to be called concurrently from different threads. However, every method invocation should give the illusion that it takes place instantaneously at some point between its invocation and its return. We formalize (concurrent) executions and implementations in Section~\ref{ssec:exec}, Section~\ref{ssec:semantic_prop} introduces a set of properties satisfied by all the  implementations we are aware of, and Section~\ref{ssec:lin} defines the standard correctness criterion for concurrent implementations of ADTs known as \emph{linearizability}~\cite{journals/toplas/HerlihyW90}.

\subsection{Executions}\label{ssec:exec}

We fix a (possibly infinite) set $\mathbb{D}$ of data values, a (possibly infinite) set $\mathbb{P}$ of priorities, a partial order $\prec$ among elements in $\mathbb{P}$, and an infinite set $\mathbb{O}$ of operation identifiers.
The latter are used to match call and return actions of the same invocation. Call actions $\textit{call}_o(\textit{put},a,p)$ and $\textit{call}_o(\textit{rm},a')$ with $a\in \mathbb{D}$, $a'\in \mathbb{D}\cup\{\textit{empty}\}$, $p \in \mathbb{P}$, and $o \in \mathbb{O}$, combine a method name and a set of arguments with an operation identifier. The return value of a remove is transformed to an argument value for uniformity~\footnote{Method return values are guessed nondeterministically, and validated at return points.
This can be handled using {\tt assume} statements, which only admit executions satisfying a given predicate.}.
The return actions are denoted in a similar way as $\textit{ret}_o(\textit{put},a,p)$ and respectively, $\textit{ret}_o(\textit{rm},a')$.

An \emph{execution} $e$ is a sequence of call and return actions which satisfy the following well-formedness properties: each return is preceded by a matching call (having the same operation identifier), and each operation identifier is used in at most one call/return. We assume every set of executions is closed under isomorphic renaming of operation identifiers. An $m(a)$-operation in an execution $e$ is an operation identifier $o$ s.t. $e$ contains the actions $\textit{call}_o(m,a)$ and $\textit{ret}_o(m,a)$.
An execution is called \emph{sequential} when no two operations overlap, i.e., each call action is immediately followed by its matching return action, and \emph{concurrent} otherwise. For readability, we write a sequential execution as a sequence of $\textit{put}(a,p)$ and $\textit{rm}(a)$ symbols representing a pair of actions $\textit{call}_o(\textit{put},a,p)\cdot \textit{ret}_o(\textit{put},a,p)$ and $\textit{call}_o(\textit{rm},a)\cdot \textit{ret}_o(\textit{rm},a)$, respectively ($o\in\mathbb{O}$). For example, given two priorities $p_1 \prec p_2$, $\textit{put}(a,p_2) \cdot \textit{put}(b,p_1) \cdot \textit{rm}(b)$ is a sequential execution of the priority queue ($\textit{rm}$ returns $b$ because it has smaller priority).

We define $\seqPQ$, the set of sequential priority queue executions, semantically via a labelled transition system (LTS, for short). An LTS is a tuple $A=(Q,\Sigma,\rightarrow,q_0)$, where $Q$ is a set of states, $\Sigma$ is an alphabet of transition labels, $\rightarrow\subseteq Q\times\Sigma\times Q$ is a transition relation, and $q_0$ is the initial state. We model the priority queue as an LTS $\textit{PQ}$ where states are mappings associating priorities in $\mathbb{P}$ with sequences of values in $\mathbb{D}$, representing a snapshot of the priority queue (for each priority, the values are ordered as they were inserted), and the transition labels are $\textit{put}(a,p)$ and $\textit{rm}(a)$. Each transition modifies the state as expected. For example, $q_1 \xrightarrow{\textit{rm}(\textit{empty})} q_2$ if $q_1 = q_2$, and $q_1$ and $q_2$ map each priority to the empty sequence $\epsilon$. Then, $\seqPQ$ is the set of traces (words) accepted by $\textit{PQ}$. %}{\color {red}$\seqPQ$ is the set of traces of $\textit{PQ}$}. {\color {red}The detailed definition of $\textit{PQ}$ can be found in the long version \cite{CONCUR2017Ahmed}.}
%{The detailed definition of $\textit{PQ}$ can be found in Appendix \ref{sec:appendix definition of seqPQ and proof of Lemma EQP rules and semantics}.}


An implementation $\mathcal{I}$ is a set of executions. Implementations represent libraries whose methods are called by external programs. In the remainder of this work, we consider only \emph{completed} executions, where each call action has a corresponding return action. This simplification is sound when the method invocations can always make progress in isolation. 
%formally, for any execution $e$ with pending operations, there exists an execution $e'$ obtained by extending $e$ only with the return actions of the pending operations of $e$. 
%Intuitively this means that methods can always return without any help from outside threads, avoiding deadlock.


%a finite set $\mathbb{M}$ of methods, and an infinite set $\mathbb{O}$ of operation (identifiers). Given $m \in \mathbb{M}$, $x \in \mathbb{D}$, and $o \in \mathbb{O}$, a call action $\textit{call}_o (m,x)$ represents an invocation to method $m$ with argument $x$, while a return action $\textit{ret}_o (m,x)$ represents a response from method $m$ with return value $x$. \footnote{Call actions with more than one arguments are similarly defined.} Here $o$ is used to match return actions to their call actions: $\textit{cal}_o (m,x)$ matches $\textit{ret}_{o'} (m',x')$, if $o=o' \wedge m=m'$. A sequential execution is a sequence of call and return actions, while each call action is immediately followed by its matching return action. Let $\cdot$ be the concatenation of sequences. To ease the reading, given a sequential execution $e=\textit{call}_{o_1}(m_1,a_1) \cdot \textit{rm}_{o_1}(m_1,b_1) \cdot \ldots \cdot \textit{call}_{o_n}(m_n,a_n) \cdot \textit{rm}_{o_n}(m_n,b_n)$, when the context is clear, we can write it as $e=m_1(a_1,b_1) \cdot \ldots \cdot m_n(a_n,b_n)$. We write $m(a,b)$ as $m(a)$ or $m(b)$, when there is no return value or there is no argument, respectively.



%A priority queue with partially-ordered priorities (priority queue for short) contains two method: $\textit{put}$ and $\textit{rm}$. A $\textit{put}$ method has two arguments, while the first argument is an item and the second argument is its priority. A $\textit{put}$ method is used to put an item into the priority queue with certain priority. Here the item is chosen from a specific (possibly infinite) data domain $\mathbb{D}$ and priority is chosen from a (possibly infinite) set $\mathbb{P}$. Moreover, there is a strict partial-order $\prec$ among elements in $\mathbb{P}$. A $\textit{rm}$ method intends to remove the item with minimal priority (w.r.t $\prec$) in priority queue and then returns it. It works as follows:

%\begin{itemize}
%\setlength{\itemsep}{0.5pt}
%\item[-] If the priority queue is empty, then $\textit{rm}$ returns $\textit{empty}$.
%
%\item[-] Else, $\textit{rm}$ choose one of minimal priority of items in priority queue, and returns the earliest putted item of this priority. Note that if there are more than one incomparable and minimal candidate priorities, then the chosen of priority is arbitrary.
%\end{itemize}


%Let us introduce the notion of sequential executions, which modelled the specification of concurrent libraries. We fix a (possibly infinite) set $\mathbb{D}$ of data values, a finite set $\mathbb{M}$ of methods, and an infinite set $\mathbb{O}$ of operation (identifiers). Given $m \in \mathbb{M}$, $x \in \mathbb{D}$, and $o \in \mathbb{O}$, a call action $\textit{call}_o (m,x)$ represents an invocation to method $m$ with argument $x$, while a return action $\textit{ret}_o (m,x)$ represents a response from method $m$ with return value $x$. \footnote{Call actions with more than one arguments are similarly defined.} Here $o$ is used to match return actions to their call actions: $\textit{cal}_o (m,x)$ matches $\textit{ret}_{o'} (m',x')$, if $o=o' \wedge m=m'$. A sequential execution is a sequence of call and return actions, while each call action is immediately followed by its matching return action. Let $\cdot$ be the concatenation of sequences. To ease the reading, given a sequential execution $e=\textit{call}_{o_1}(m_1,a_1) \cdot \textit{rm}_{o_1}(m_1,b_1) \cdot \ldots \cdot \textit{call}_{o_n}(m_n,a_n) \cdot \textit{rm}_{o_n}(m_n,b_n)$, when the context is clear, we can write it as $e=m_1(a_1,b_1) \cdot \ldots \cdot m_n(a_n,b_n)$. We write $m(a,b)$ as $m(a)$ or $m(b)$, when there is no return value or there is no argument, respectively.

\subsection{Semantic Properties of Priority Queues}\label{ssec:semantic_prop}

We define two properties which are %satisfied by priority queue implementations and which are 
important for our results: (1) \emph{data independence}~\cite{conf/popl/Wolper86,conf/tacas/AbdullaHHJR13} states that priority queue behaviors do not depend on the actual values which are added to the queue, and (2) \emph{closure under projection}~\cite{DBLP:conf/icalp/BouajjaniEEH15} states that executions remain valid by removing all the operations adding or removing certain values.
%remove operations can return the same values even if certain values are projected out from the priority queue state.
%no matter how many other different values are in the queue, provided that they don't have more important priorities.

%Data-independence \cite{Wolper:1986} can be used to effectively handle unbounded data domain. In this paper, we slightly modify the notion of data-independence in \cite{Wolper:1986} and propose data-independence for priority queues. Let $\_$ denote an element, of which the value is irrelevant.
An execution $e$ is \emph{data-differentiated} if every value is added at most once, i.e., for each $d \in \mathbb{D}$, $e$ contains at most one action $\textit{call}_o(\textit{put},d,p)$ with $o\in\mathbb{O}$ and $p\in \mathbb{P}$. Note that this property concerns only values, a data-differentiated execution $e$ may contain more than one value with the same priority. The subset of data-differentiated executions of a set of executions $E$ is denoted by $E_{\neq}$.

A renaming function $r$ is a function from $\mathbb{D}$ to $\mathbb{D}$. Given an execution $e$, we denote by $r(e)$ the execution obtained from $e$ by replacing every data value $x$ by $r(x)$. Note that $r$ renames only the values and keeps the priorities unchanged. Intuitively, renaming values has no influence on the behavior of the priority queue, contrary to renaming priorities.

%\vspace{-6pt}
\begin{definition}\label{def:priority-value data-independence}
A set of executions $E$ is \emph{data independent} iff
\begin{itemize}
\setlength{\itemsep}{0.5pt}
\item[-] for all $e \in E$, there exists $e' \in E_{\neq}$ and a renaming function $r$, such that $e=r(e')$,

\item[-] for all $e \in E$ and for all renamings $r$, $r(e) \in E$.
\end{itemize}
\end{definition}

The following lemma is a direct consequence of definitions.

\begin{lemma}
$\seqPQ$ is data independent.
\end{lemma}

Beyond sequential executions, every concurrent priority queue implementation that we are aware of is data-independent. From now on, we consider only data-independent implementations. This assumption enables a reduction from checking the correctness of an implementation $\mathcal{I}$ to checking the correctness of its data-differentiated executions in $\mathcal{I}_{\neq}$.

Besides data independence, the sequential executions of the priority queue satisfy the following closure property: an execution remains valid when removing all the operations with an argument in some set of values $D \subseteq \mathbb{D}$ and any $\textit{rm}(\textit{empty})$ operation (since they are read-only and they don't affect the queue's state).
To distinguish between different $\textit{rm}(\textit{empty})$ operations while simplifying the technical exposition, we assume that they receive as argument a value, i.e., call actions are of the form $\textit{call}_o(\textit{rm},\textit{empty},a)$ for some $a\in \mathbb{D}$. We will make explicit this argument only when needed in our technical development. The projection $e \vert D$ of an execution $e$ to a set of values $D \subseteq \mathbb{D}$ is obtained from $e$ by erasing all the call/return actions with an argument not in $D$. We write $e \setminus x$ for the projection $e \vert_{ \mathbb{D} \setminus \{ x \} }$. Let $\textit{proj}(e)$ be the set of all projections of $e$ to a set of values $D \subseteq \mathbb{D}$. 
%{\color {red}The following lemma states that $\seqPQ$ is closed under projection.} 

%The proof of the following lemma can be found in Appendix \ref{sec:appendix proofs in section priority queue and data-independence}.

%\begin{lemma}\label{lem:closure_proj}
%$\seqPQ$ is closed under projection, i.e., $\textit{proj}(e)\subseteq \seqPQ$ for each $e\in \seqPQ$.
%\end{lemma}
\begin{restatable}{lemma}{EPQClosedUnderProjection}
\label{lem:closure_proj}
$\seqPQ$ is closed under projection, i.e., $\textit{proj}(e)\subseteq \seqPQ$ for each $e\in \seqPQ$.
\end{restatable}


\subsection{Linearizability}\label{ssec:lin}

%A (concurrent) execution $e$ is a sequence of call and return actions which satisfy a well-formedness property: every return has a matching call action before it in $e$, and an operation $o$ can be used only twice in $e$, once in a call action, and once in a return action. The definition of data-differentiated, renaming function, data-independence and projection extends to (concurrent) executions. For instance, an execution is data-differentiated if, for all $d \in \mathbb{D}$, there is at most one $\textit{cal}_{\_}(\textit{put},d,\_)$.
%
%An implementation $\mathcal{I}$ is a set of concurrent executions. Implementations represent libraries whose methods are called by external programs. In the remainder of this work, we consider only completed executions, where each call action has a corresponding return action. This simplification is sound when implementation methods can always make progress in isolation \cite{Henzinger:2013}: formally, for any execution $e$ with pending operations, there exists an execution $e'$ obtained by extending $e$ only with the return actions of the pending operations of $e$. Intuitively this means that methods can always return without any help from outside threads, avoiding deadlock.
We recall the notion of \emph{linearizability}~\cite{journals/toplas/HerlihyW90} which is the \emph{de facto} standard correctness condition for concurrent data structures.
Given an execution $e$, the happen-before relation $<_{\textit{hb}}$ between operations~\footnote{In general, we refer to operations using their identifiers.} is defined as follows: $o_1 <_{\textit{hb}} o_2$, if the return action of $o_1$ occurs before the call action of $o_2$ in $e$. The happens-before relation is an interval order \cite{DBLP:conf/popl/BouajjaniEEH15}: for distinct $o_1,o_2,o_3,o_4$, if $o_1 <_{\textit{hb}} o_2$ and $o_3 <_{\textit{hb}} o_4$, then either $o_1 <_{\textit{hb}} o_4$, or $o_3 <_{\textit{hb}} o_2$. Intuitively, this comes from the fact that concurrent threads share a notion of global time.

Given a (concurrent) execution $e$ and a sequential execution $s$, we say that $e$ is linearizable w.r.t $s$, denoted $e \sqsubseteq s$, if there is a bijection $f: O_1 \rightarrow O_2$, where $O_1$ and $O_2$ are the set of operations of $e$ and $s$, respectively, such that (1) the call and return actions with identifier $o$ and $f(o)$, respectively, are the same
%{\color{blue}$o$ and $f(o)$ have the same call and return actions}{\color {red}$o$ and $f(o)$ is the same operation}\footnote{}, 
and (2) if $o_1 <_{\textit{hb}} o_2$, then $f(o_1) <_{\textit{hb}} f(o_2)$.
A (concurrent) execution $e$ is linearizable w.r.t. a set $S$ of sequential executions, denoted $e \sqsubseteq S$, if there exists $s \in S$ such that $e \sqsubseteq s$. A set of concurrent executions $E$ is linearizable w.r.t. $S$, denoted $E \sqsubseteq S$, if $e \sqsubseteq S$ for all $e \in E$.

The following lemma states that by data-independence, it is enough to consider only data-differentiated executions when checking linearizability. %(see Appendix \ref{sec:appendix proofs in section priority queue and data-independence}). 
%This is similar to that in \cite{conf/tacas/AbdullaHHJR13,DBLP:conf/icalp/BouajjaniEEH15}, where they use the notion of data-independence in \cite{conf/popl/Wolper86}.
Section~\ref{sec:checking inclusion by recursive procedure} will focus on characterizing linearizability for data-differentiated executions. %The proof of this lemma can be found in Appendix \ref{sec:appendix in section data-independence of EPQ}.

\begin{restatable}{lemma}{DataDifferentiatedisEnoughforPQ}
\label{lemma:data differentiated is enough for PQ}
A data-independent implementation $\mathcal{I}$ is linearizable w.r.t. a data-independent set $S$ of sequential executions, if and only if $\mathcal{I}_{\neq}$ is linearizable w.r.t. $S_{\neq}$.
\end{restatable}


